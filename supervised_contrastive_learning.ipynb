{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised_contrastive_learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rameshavinash94/-Practice-transfer-learning-and-supervised-contrastive-learning/blob/main/supervised_contrastive_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Supervised Contrastive Learning**"
      ],
      "metadata": {
        "id": "SW46DOpVLBtr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egVZt4sL8LHd",
        "outputId": "07988194-30e5-49b7-b7db-448d2c59390f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 28.8 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 36.2 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 37.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 40.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 27.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 112 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 143 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 194 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 225 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 256 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 276 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 286 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 307 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 337 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 358 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 368 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 389 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 399 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 430 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 440 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 450 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 460 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 471 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 481 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 501 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 512 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 522 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 532 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 542 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 552 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 563 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 573 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 583 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 604 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 614 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 624 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 634 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 645 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 655 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 675 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 686 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 696 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 706 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 716 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 727 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 737 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 747 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 757 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 768 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 778 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 788 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 798 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 808 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 819 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 829 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 849 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 860 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 870 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 880 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 890 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 901 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 911 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 921 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 931 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 942 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 952 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 962 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 972 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 983 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 993 kB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.0 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 28.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 28.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "LeL140pn8U5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "# Load the train and test data splits\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Display shapes of train and test datasets\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwSyQGo98WWT",
        "outputId": "eef01d86-7139-4c01-8318-8afb2b230934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using image data augmentation"
      ],
      "metadata": {
        "id": "4sY8aqajLHla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.02),\n",
        "        layers.RandomWidth(0.2),\n",
        "        layers.RandomHeight(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Setting the state of the normalization layer.\n",
        "data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "27AVgk0h8YEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the encoder model"
      ],
      "metadata": {
        "id": "jSP_V5eFLMv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_encoder():\n",
        "    resnet = keras.applications.ResNet50V2(\n",
        "        include_top=False, weights=None, input_shape=input_shape, pooling=\"avg\"\n",
        "    )\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n",
        "\n",
        "\n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n",
        "\n",
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPFgGnRC8Z1y",
        "outputId": "294b65b6-b93b-4834-adbc-7b81726bb297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " sequential (Sequential)     (None, 32, 32, 3)         7         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,564,807\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the classification model"
      ],
      "metadata": {
        "id": "woaawzv8LQki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "qN_uzcrl8cnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=1)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIBXyO0T8fjZ",
        "outputId": "c7a683ce-1c5e-4740-adfa-a9fa6d2ab941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,619,025\n",
            "Trainable params: 24,573,578\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "189/189 [==============================] - 68s 249ms/step - loss: 1.9484 - sparse_categorical_accuracy: 0.2843\n",
            "313/313 [==============================] - 6s 14ms/step - loss: 1.7485 - sparse_categorical_accuracy: 0.3637\n",
            "Test accuracy: 36.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 2: Use supervised contrastive learning"
      ],
      "metadata": {
        "id": "rBtKhe4E8--C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "CfLn_CuL8hd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=50\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8KwN6q39BPj",
        "outputId": "3f1ec250-51f2-4d2d-be4a-ded0eb551ede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2048)             23564807  \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               262272    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,827,079\n",
            "Trainable params: 23,781,632\n",
            "Non-trainable params: 45,447\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "189/189 [==============================] - 31s 136ms/step - loss: 5.3957\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 24s 125ms/step - loss: 5.1514\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 5.0356\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 25s 133ms/step - loss: 4.9346\n",
            "Epoch 5/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.8410\n",
            "Epoch 6/50\n",
            "189/189 [==============================] - 23s 119ms/step - loss: 4.7622\n",
            "Epoch 7/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.6948\n",
            "Epoch 8/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 4.6288\n",
            "Epoch 9/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.5794\n",
            "Epoch 10/50\n",
            "189/189 [==============================] - 23s 119ms/step - loss: 4.5262\n",
            "Epoch 11/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.4894\n",
            "Epoch 12/50\n",
            "189/189 [==============================] - 25s 131ms/step - loss: 4.4577\n",
            "Epoch 13/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 4.4164\n",
            "Epoch 14/50\n",
            "189/189 [==============================] - 23s 119ms/step - loss: 4.3720\n",
            "Epoch 15/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.3337\n",
            "Epoch 16/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.3089\n",
            "Epoch 17/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.2833\n",
            "Epoch 18/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.2466\n",
            "Epoch 19/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.2325\n",
            "Epoch 20/50\n",
            "189/189 [==============================] - 23s 121ms/step - loss: 4.1964\n",
            "Epoch 21/50\n",
            "189/189 [==============================] - 23s 119ms/step - loss: 4.1892\n",
            "Epoch 22/50\n",
            "189/189 [==============================] - 23s 121ms/step - loss: 4.1615\n",
            "Epoch 23/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.1352\n",
            "Epoch 24/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.1141\n",
            "Epoch 25/50\n",
            "189/189 [==============================] - 22s 119ms/step - loss: 4.0898\n",
            "Epoch 26/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.0743\n",
            "Epoch 27/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 4.0713\n",
            "Epoch 28/50\n",
            "189/189 [==============================] - 23s 119ms/step - loss: 4.0419\n",
            "Epoch 29/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 4.0231\n",
            "Epoch 30/50\n",
            "189/189 [==============================] - 22s 119ms/step - loss: 4.0098\n",
            "Epoch 31/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.9881\n",
            "Epoch 32/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 3.9702\n",
            "Epoch 33/50\n",
            "189/189 [==============================] - 23s 121ms/step - loss: 3.9672\n",
            "Epoch 34/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 3.9432\n",
            "Epoch 35/50\n",
            "189/189 [==============================] - 23s 122ms/step - loss: 3.9372\n",
            "Epoch 36/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 3.9222\n",
            "Epoch 37/50\n",
            "189/189 [==============================] - 23s 121ms/step - loss: 3.9075\n",
            "Epoch 38/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.9006\n",
            "Epoch 39/50\n",
            "189/189 [==============================] - 22s 117ms/step - loss: 3.8868\n",
            "Epoch 40/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 3.8702\n",
            "Epoch 41/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.8550\n",
            "Epoch 42/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.8445\n",
            "Epoch 43/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.8387\n",
            "Epoch 44/50\n",
            "189/189 [==============================] - 23s 121ms/step - loss: 3.8097\n",
            "Epoch 45/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.8215\n",
            "Epoch 46/50\n",
            "189/189 [==============================] - 22s 117ms/step - loss: 3.8109\n",
            "Epoch 47/50\n",
            "189/189 [==============================] - 22s 117ms/step - loss: 3.7985\n",
            "Epoch 48/50\n",
            "189/189 [==============================] - 23s 120ms/step - loss: 3.7761\n",
            "Epoch 49/50\n",
            "189/189 [==============================] - 22s 118ms/step - loss: 3.7735\n",
            "Epoch 50/50\n",
            "189/189 [==============================] - 22s 119ms/step - loss: 3.7606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the classifier with the frozen encoder"
      ],
      "metadata": {
        "id": "Dk9_bFL_9GhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvkGdfZD9D7-",
        "outputId": "eef12908-8875-401e-bfa3-54ae1327999a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "189/189 [==============================] - 10s 38ms/step - loss: 1.8558 - sparse_categorical_accuracy: 0.3127\n",
            "Epoch 2/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.7266 - sparse_categorical_accuracy: 0.3471\n",
            "Epoch 3/50\n",
            "189/189 [==============================] - 8s 43ms/step - loss: 1.7063 - sparse_categorical_accuracy: 0.3571\n",
            "Epoch 4/50\n",
            "189/189 [==============================] - 8s 45ms/step - loss: 1.7010 - sparse_categorical_accuracy: 0.3595\n",
            "Epoch 5/50\n",
            "189/189 [==============================] - 7s 37ms/step - loss: 1.6882 - sparse_categorical_accuracy: 0.3641\n",
            "Epoch 6/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6894 - sparse_categorical_accuracy: 0.3659\n",
            "Epoch 7/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6822 - sparse_categorical_accuracy: 0.3695\n",
            "Epoch 8/50\n",
            "189/189 [==============================] - 8s 43ms/step - loss: 1.6754 - sparse_categorical_accuracy: 0.3735\n",
            "Epoch 9/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6787 - sparse_categorical_accuracy: 0.3702\n",
            "Epoch 10/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6772 - sparse_categorical_accuracy: 0.3693\n",
            "Epoch 11/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6673 - sparse_categorical_accuracy: 0.3718\n",
            "Epoch 12/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6681 - sparse_categorical_accuracy: 0.3732\n",
            "Epoch 13/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6734 - sparse_categorical_accuracy: 0.3728\n",
            "Epoch 14/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6673 - sparse_categorical_accuracy: 0.3740\n",
            "Epoch 15/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6693 - sparse_categorical_accuracy: 0.3735\n",
            "Epoch 16/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6632 - sparse_categorical_accuracy: 0.3768\n",
            "Epoch 17/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6621 - sparse_categorical_accuracy: 0.3754\n",
            "Epoch 18/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6666 - sparse_categorical_accuracy: 0.3741\n",
            "Epoch 19/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6641 - sparse_categorical_accuracy: 0.3762\n",
            "Epoch 20/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6599 - sparse_categorical_accuracy: 0.3781\n",
            "Epoch 21/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6619 - sparse_categorical_accuracy: 0.3767\n",
            "Epoch 22/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6596 - sparse_categorical_accuracy: 0.3761\n",
            "Epoch 23/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6585 - sparse_categorical_accuracy: 0.3806\n",
            "Epoch 24/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6620 - sparse_categorical_accuracy: 0.3768\n",
            "Epoch 25/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6531 - sparse_categorical_accuracy: 0.3774\n",
            "Epoch 26/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6586 - sparse_categorical_accuracy: 0.3811\n",
            "Epoch 27/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6585 - sparse_categorical_accuracy: 0.3774\n",
            "Epoch 28/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6569 - sparse_categorical_accuracy: 0.3790\n",
            "Epoch 29/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6561 - sparse_categorical_accuracy: 0.3767\n",
            "Epoch 30/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6534 - sparse_categorical_accuracy: 0.3791\n",
            "Epoch 31/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6583 - sparse_categorical_accuracy: 0.3773\n",
            "Epoch 32/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6554 - sparse_categorical_accuracy: 0.3797\n",
            "Epoch 33/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6567 - sparse_categorical_accuracy: 0.3778\n",
            "Epoch 34/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6604 - sparse_categorical_accuracy: 0.3763\n",
            "Epoch 35/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6529 - sparse_categorical_accuracy: 0.3782\n",
            "Epoch 36/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6555 - sparse_categorical_accuracy: 0.3785\n",
            "Epoch 37/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6556 - sparse_categorical_accuracy: 0.3776\n",
            "Epoch 38/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6502 - sparse_categorical_accuracy: 0.3808\n",
            "Epoch 39/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6538 - sparse_categorical_accuracy: 0.3801\n",
            "Epoch 40/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6542 - sparse_categorical_accuracy: 0.3766\n",
            "Epoch 41/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6514 - sparse_categorical_accuracy: 0.3837\n",
            "Epoch 42/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6525 - sparse_categorical_accuracy: 0.3816\n",
            "Epoch 43/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6567 - sparse_categorical_accuracy: 0.3809\n",
            "Epoch 44/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6523 - sparse_categorical_accuracy: 0.3790\n",
            "Epoch 45/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6505 - sparse_categorical_accuracy: 0.3815\n",
            "Epoch 46/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6546 - sparse_categorical_accuracy: 0.3753\n",
            "Epoch 47/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6521 - sparse_categorical_accuracy: 0.3769\n",
            "Epoch 48/50\n",
            "189/189 [==============================] - 7s 36ms/step - loss: 1.6505 - sparse_categorical_accuracy: 0.3828\n",
            "Epoch 49/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6495 - sparse_categorical_accuracy: 0.3822\n",
            "Epoch 50/50\n",
            "189/189 [==============================] - 7s 35ms/step - loss: 1.6522 - sparse_categorical_accuracy: 0.3796\n",
            "313/313 [==============================] - 5s 13ms/step - loss: 1.5547 - sparse_categorical_accuracy: 0.4045\n",
            "Test accuracy: 40.45%\n"
          ]
        }
      ]
    }
  ]
}